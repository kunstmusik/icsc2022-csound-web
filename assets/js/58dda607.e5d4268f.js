"use strict";(self.webpackChunkicsc_2022_csound_web=self.webpackChunkicsc_2022_csound_web||[]).push([[424],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>m});var i=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,o=function(e,t){if(null==e)return{};var n,i,o={},a=Object.keys(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=i.createContext({}),l=function(e){var t=i.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},d=function(e){var t=l(e.components);return i.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},p=i.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,c=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),p=l(n),m=o,h=p["".concat(c,".").concat(m)]||p[m]||u[m]||a;return n?i.createElement(h,r(r({ref:t},d),{},{components:n})):i.createElement(h,r({ref:t},d))}));function m(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,r=new Array(a);r[0]=p;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var l=2;l<a;l++)r[l]=n[l];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}p.displayName="MDXCreateElement"},1109:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>u,frontMatter:()=>a,metadata:()=>s,toc:()=>l});var i=n(7462),o=(n(7294),n(3905));const a={sidebar_position:4},r="Tutorial 3 - Microphone/Midi interaction",s={unversionedId:"tutorial3-microphone-midi-interaction",id:"tutorial3-microphone-midi-interaction",title:"Tutorial 3 - Microphone/Midi interaction",description:"In this tutorial we are going to learn about ways to interact with csound using human interface devices, like a microphone",source:"@site/docs/tutorial3-microphone-midi-interaction.md",sourceDirName:".",slug:"/tutorial3-microphone-midi-interaction",permalink:"/icsc2022-csound-web/tutorial3-microphone-midi-interaction",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/tutorial3-microphone-midi-interaction.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"Tutorial 2 - Interacting with Csound",permalink:"/icsc2022-csound-web/tutorial2-interacting-with-csound"},next:{title:"Tutorial 4 - FileSystem",permalink:"/icsc2022-csound-web/tutorial4-filesystem"}},c={},l=[{value:"Step 1 - Connect your midi device",id:"step-1---connect-your-midi-device",level:2},{value:"Step 2 - Detect MIDI events",id:"step-2---detect-midi-events",level:2},{value:"Step 3 - connect microphone",id:"step-3---connect-microphone",level:2}],d={toc:l};function u(e){let{components:t,...n}=e;return(0,o.kt)("wrapper",(0,i.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"tutorial-3---microphonemidi-interaction"},"Tutorial 3 - Microphone/Midi interaction"),(0,o.kt)("p",null,"In this tutorial we are going to learn about ways to interact with csound using human interface devices, like a microphone\nor a midi keyboard."),(0,o.kt)("h2",{id:"step-1---connect-your-midi-device"},"Step 1 - Connect your midi device"),(0,o.kt)("p",null,"For this tutorial you'll need a midi device connected. This can either be a physical midi-controller, or a virtual midi device. Because of security concerns, it's not currently possible to create a \"real\" virtual midi device from inside the browser."),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"\"While it's not possible to create a virtual midi device from within the browser, it's still possible to create midi-event emitting elements. This is what the virtual midi-keyboard does in the web-ide, it uses ",(0,o.kt)("inlineCode",{parentName:"p"},"await csound.midiMessage(144, midiNumber, 64)")," to programatically send a NOTE_ON event with a subsequent ",(0,o.kt)("inlineCode",{parentName:"p"},"await csound.midiMessage(128, midiNumber, 64)"),' NOTE_OFF event."')),(0,o.kt)("p",null,"If you don't have a physical midi-keyboard at hand, we can recommend these alternatives:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"OSX ",(0,o.kt)("inlineCode",{parentName:"li"},"midikeys")," ",(0,o.kt)("a",{parentName:"li",href:"https://flit.github.io/projects/midikeys/"},"https://flit.github.io/projects/midikeys/")),(0,o.kt)("li",{parentName:"ul"},"Windows ",(0,o.kt)("inlineCode",{parentName:"li"},"loopMIDI")," ",(0,o.kt)("a",{parentName:"li",href:"https://www.tobias-erichsen.de/software/loopmidi.html"},"https://www.tobias-erichsen.de/software/loopmidi.html")),(0,o.kt)("li",{parentName:"ul"},"Linux ",(0,o.kt)("inlineCode",{parentName:"li"},"vmpk")," ",(0,o.kt)("a",{parentName:"li",href:"https://vmpk.sourceforge.io/"},"https://vmpk.sourceforge.io/")," for ubuntu users ",(0,o.kt)("inlineCode",{parentName:"li"},"sudo apt-get install vmpk"),".")),(0,o.kt)("h2",{id:"step-2---detect-midi-events"},"Step 2 - Detect MIDI events"),(0,o.kt)("p",null,"If you are unsure if csound is detecting midi events, the following snippet could help with debugging. Note that csound-wasm doesn't implicitly ask for access to midi devices. Just like is the case for native csound, we need to provide an option ",(0,o.kt)("inlineCode",{parentName:"p"},"-M0")," (or the equivalent ",(0,o.kt)("inlineCode",{parentName:"p"},"-Ma"),") where 0 tells csound to map midi events to all instruments, for specific midi to instrument mapping; change 0 to the instrument number that you wish to be triggered from midi events.\nWhen using ",(0,o.kt)("inlineCode",{parentName:"p"},"-M0")," it's possible to use the opcode ",(0,o.kt)("inlineCode",{parentName:"p"},"massign")," in global scope to manually map midi channel to a specific numbered csound instrument."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},'const midiEventTest = `\n<CsoundSynthesizer>\n<CsOptions>\n-M0\n</CsOptions>\n<CsInstruments>\nsr = 44100\nksmps = 128\nnchnls = 2\n0dbfs = 1\n\n\ninstr 1\n\n  kstatus, kchan, kdata1, kdata2 midiin\n\n  ktrig changed kstatus\n\n  if ktrig == 1 then\n    printks "kstatus= %d, kchan = %d, kdata1 = %d, kdata2 = %d\\\\n", 0, kstatus, kchan, kdata1, kdata2\n  endif\n\nendin\n\n</CsInstruments>\n<CsScore>\nf 0 3600\n\n</CsScore>\n</CsoundSynthesizer>\n`;\n\nlet csound = null;\n\nconst startCsound = async () => {\n  if (csound) {\n    return;\n  }\n\n  console.log("Starting Csound...");\n\n  csound = await Csound();\n\n  await csound.compileCsdText(midiEventTest);\n  await csound.start();\n};\n\ndocument.querySelector("#startButton").addEventListener("click", startCsound);\n')),(0,o.kt)("p",null,"If the midi is working well, you should see something similar to the following in your browser console."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-console"},"--Csound version 6.18 (double samples) Oct  9 2022\neventemitter3.min.js:1 [commit: HEAD]\neventemitter3.min.js:1 libsndfile-1.1.0\neventemitter3.min.js:1 graphics suppressed, ascii substituted\neventemitter3.min.js:1 sr = 48000.0, kr = 375.000, ksmps = 128\neventemitter3.min.js:1 0dBFS level = 1.0, A4 tuning = 440.0\neventemitter3.min.js:1 orch now loaded\neventemitter3.min.js:1 audio buffered in 256 sample-frame blocks\neventemitter3.min.js:1 SECTION 1:\neventemitter3.min.js:1   rtevent:      T  5.733 TT  5.733 M:  0.00000  0.00000\neventemitter3.min.js:1 new MIDI alloc for instr 1:\neventemitter3.min.js:1 kstatus= 208, kchan = 1, kdata1 = 0, kdata2 = 0\neventemitter3.min.js:1 kstatus= 0, kchan = 1, kdata1 = 0, kdata2 = 0\neventemitter3.min.js:1 kstatus= 208, kchan = 1, kdata1 = 1, kdata2 = 0\neventemitter3.min.js:1 kstatus= 0, kchan = 1, kdata1 = 1, kdata2 = 0\n")),(0,o.kt)("p",null,"Note that it's also possible to pass csound options directly to csound, in the case of ",(0,o.kt)("inlineCode",{parentName:"p"},"-M0")," we could've done this"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},'await csound.compileCsdText(midiEventTest);\nawait csound.setOption("-M0");\nawait csound.start();\n')),(0,o.kt)("h2",{id:"step-3---connect-microphone"},"Step 3 - connect microphone"),(0,o.kt)("p",null,"Within the browser environment, we are somewhat limited in which devices we are allowed to access. The audio input device which the browser will grab will be determined by the default audio input set by the operating system. Such is the case for any browser based video conference application, the browser will grab the default video and audio input presented to it by the operating system."),(0,o.kt)("p",null,"By default, Csound will not prompt the user for access to the audio input device except it is configured to do so.\nThe following ways can be used to tell Csound to ask for access for audio input:"),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"-idac")," flag is present within the CsOptions xml tag."),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("inlineCode",{parentName:"li"},"-idac")," flag is passed to the csound object ",(0,o.kt)("inlineCode",{parentName:"li"},'await csound.setOption("-idac");')),(0,o.kt)("li",{parentName:"ol"},"An explicit call is made to the csound object for enabling audioInput ",(0,o.kt)("inlineCode",{parentName:"li"},"await csound.enableAudioInput();"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-js"},'const micTest = `\n      <CsoundSynthesizer>\n        <CsOptions>\n        -odac -iadc --daemon\n        </CsOptions>\n        <CsInstruments>\n          0dbfs=1\n          nchnls_i=1\n          nchnls=2\n          instr 1\n            ain = inch(1)\n            al, ar  reverbsc ain, ain, 0.85, 10000\n            out(al, ar)\n          endin\n          schedule(1, 0, -1)\n        </CsInstruments>\n        <CsScore>\n        </CsScore>\n      </CsoundSynthesizer>\n     `;\n\nlet csound = null;\n\nconst startCsound = async () => {\n  if (csound) {\n    return;\n  }\n\n  console.log("Starting Csound...");\n\n  csound = await Csound();\n\n  await csound.compileCsdText(micTest);\n  await csound.start();\n};\n\ndocument.querySelector("#startButton").addEventListener("click", startCsound);\n')),(0,o.kt)("p",null,"When running this example, a notification alert should appear in the browser window, asking permission for access to the microphone. As soon as permission is given or rejected, csound will start."))}u.isMDXComponent=!0}}]);